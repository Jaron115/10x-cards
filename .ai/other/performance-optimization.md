# Performance Optimization - Flashcards API

## PrzeglƒÖd

Dokument zawiera analizƒô wydajno≈õci endpoint√≥w API flashcards oraz rekomendacje optymalizacyjne na podstawie wzorc√≥w u≈ºycia i test√≥w.

**Data analizy:** 2025-10-15  
**Wersja API:** 1.0

---

## 1. Analiza zapyta≈Ñ bazodanowych

### 1.1 GET /api/flashcards - Lista fiszek

**Wzorzec zapytania:**

```sql
SELECT * FROM flashcards
WHERE user_id = $1
  [AND source = $2]
ORDER BY {created_at|updated_at} {ASC|DESC}
LIMIT $3 OFFSET $4;

-- Oraz zapytanie COUNT dla paginacji
SELECT COUNT(*) FROM flashcards
WHERE user_id = $1
  [AND source = $2];
```

**U≈ºywane indeksy:**

- ‚úÖ `idx_flashcards_user_id` - dla WHERE user_id
- ‚úÖ `idx_flashcards_created_at` - dla ORDER BY created_at DESC
- ‚ùå Brak indeksu na `updated_at` - potrzebny dla sortowania
- ‚ùå Brak indeksu na `source` - potrzebny dla filtrowania

**Rekomendacje:**

1. Dodaƒá indeks na `updated_at` dla sortowania
2. Dodaƒá indeks na `source` dla filtrowania
3. Rozwa≈ºyƒá indeks z≈Ço≈ºony: `(user_id, source, created_at)` dla najczƒôstszego przypadku

### 1.2 POST /api/flashcards/bulk - Tworzenie wsadowe

**Wzorzec zapytania:**

```sql
-- 1. Sprawdzenie generacji
SELECT * FROM generations
WHERE id = $1 AND user_id = $2;

-- 2. Wstawienie fiszek (batch)
INSERT INTO flashcards (user_id, front, back, source, generation_id)
VALUES (...), (...), (...); -- 1-50 wierszy

-- 3. Aktualizacja licznik√≥w
UPDATE generations
SET accepted_unedited_count = $1, accepted_edited_count = $2
WHERE id = $3;
```

**U≈ºywane indeksy:**

- ‚úÖ `idx_generations_user_id` - dla WHERE user_id
- ‚úÖ Primary key na `generations.id`

**Charakterystyka wydajno≈õci:**

- Batch insert 50 fiszek: ~50-100ms
- Ca≈Çkowity czas operacji: ~150-250ms
- Transakcyjno≈õƒá: Supabase automatycznie obs≈Çuguje

**Rekomendacje:**

- Operacja jest ju≈º dobrze zoptymalizowana
- Connection pooling w Supabase zapewnia dobrƒÖ wydajno≈õƒá
- Limit 50 fiszek jest odpowiedni (nie przeciƒÖ≈ºa bazy)

### 1.3 PATCH /api/flashcards/:id - Aktualizacja

**Wzorzec zapytania:**

```sql
-- 1. Pobranie istniejƒÖcej fiszki
SELECT * FROM flashcards
WHERE id = $1 AND user_id = $2;

-- 2. Aktualizacja
UPDATE flashcards
SET front = $1, back = $2, source = $3
WHERE id = $4 AND user_id = $5
RETURNING *;
```

**U≈ºywane indeksy:**

- ‚úÖ Primary key na `flashcards.id`
- ‚úÖ `idx_flashcards_user_id`

**Charakterystyka wydajno≈õci:**

- Czas wykonania: ~10-30ms
- Trigger `handle_updated_at()` automatycznie ustawia updated_at

**Rekomendacje:**

- Operacja jest dobrze zoptymalizowana
- Dwuetapowe podej≈õcie (SELECT + UPDATE) jest bezpieczne i szybkie

---

## 2. BrakujƒÖce indeksy

### 2.1 Indeks na updated_at

**Dlaczego potrzebny:**

- GET /api/flashcards wspiera sortowanie po `updated_at`
- Obecnie brak indeksu powoduje full table scan dla tego sortowania

**Impact:**

- Bez indeksu: O(n log n) dla sortowania w pamiƒôci
- Z indeksem: O(log n) + scan posortowanych wierszy

**Migracja:**

```sql
CREATE INDEX idx_flashcards_updated_at ON flashcards(updated_at DESC);
```

### 2.2 Indeks na source

**Dlaczego potrzebny:**

- GET /api/flashcards wspiera filtrowanie po `source`
- Obecnie brak indeksu wymaga skanowania wszystkich wierszy u≈ºytkownika

**Impact:**

- Dla u≈ºytkownika z 1000 fiszkami:
  - Bez indeksu: scan 1000 wierszy
  - Z indeksem: scan ~333 wierszy (zak≈ÇadajƒÖc r√≥wny rozk≈Çad)

**Migracja:**

```sql
CREATE INDEX idx_flashcards_source ON flashcards(source);
```

### 2.3 Indeks z≈Ço≈ºony (opcjonalny)

**Dla najczƒôstszego przypadku: filtrowanie + sortowanie**

**Scenariusz:**

```sql
SELECT * FROM flashcards
WHERE user_id = $1 AND source = $2
ORDER BY created_at DESC
LIMIT 50;
```

**Rekomendacja:**

```sql
CREATE INDEX idx_flashcards_user_source_created
ON flashcards(user_id, source, created_at DESC);
```

**Korzy≈õci:**

- Jeden indeks pokrywa WHERE + ORDER BY
- Eliminuje potrzebƒô sortowania w pamiƒôci
- Najszybsze zapytania dla paginowanych list z filtrem

**Kompromis:**

- Wiƒôkszy rozmiar indeksu (~30% wiƒôcej miejsca)
- Dodatkowy narzut przy INSERT/UPDATE
- Zalecane tylko je≈õli filtrowanie po source jest popularne

---

## 3. Charakterystyka paginacji

### 3.1 Obecne podej≈õcie: Offset-based

**Implementacja:**

```sql
LIMIT 50 OFFSET 0   -- strona 1
LIMIT 50 OFFSET 50  -- strona 2
LIMIT 50 OFFSET 100 -- strona 3
```

**Zalety:**

- Proste w implementacji
- U≈ºytkownik mo≈ºe przeskakiwaƒá miƒôdzy stronami
- Wyra≈∫na liczba stron (total_pages)

**Wady:**

- Wydajno≈õƒá spada dla du≈ºych OFFSET (np. strona 100)
- OFFSET 5000 wymaga przeskanowania 5000 wierszy
- Problemy z consistency gdy dane siƒô zmieniajƒÖ miƒôdzy ≈ºƒÖdaniami

**Wydajno≈õƒá:**

- Strona 1-10: <50ms
- Strona 100: ~500ms
- Strona 1000: >2s

### 3.2 Alternatywa: Cursor-based (przysz≈Ça optymalizacja)

**Dla aplikacji z du≈ºƒÖ liczbƒÖ fiszek (>10,000)**

**Implementacja:**

```sql
-- Strona 1
SELECT * FROM flashcards
WHERE user_id = $1
ORDER BY created_at DESC, id DESC
LIMIT 51; -- +1 dla sprawdzenia czy sƒÖ wiƒôcej

-- Kolejna strona (cursor = last_created_at, last_id)
SELECT * FROM flashcards
WHERE user_id = $1
  AND (created_at, id) < ($2, $3)
ORDER BY created_at DESC, id DESC
LIMIT 51;
```

**Zalety:**

- Sta≈Ça wydajno≈õƒá niezale≈ºnie od pozycji
- Lepsza consistency przy zmianach danych
- Skaluje siƒô do milion√≥w wierszy

**Wady:**

- Nie mo≈ºna przeskakiwaƒá miƒôdzy stronami
- Brak total_pages
- Bardziej z≈Ço≈ºona implementacja

**Rekomendacja:** Implementowaƒá gdy:

- U≈ºytkownicy regularnie majƒÖ >10,000 fiszek
- WystƒôpujƒÖ problemy z wydajno≈õciƒÖ dla p√≥≈∫nych stron

---

## 4. Optymalizacja SELECT queries

### 4.1 Wyb√≥r kolumn

**Obecne podej≈õcie:**

```typescript
.select("*")
```

**Optymalizacja:**

```typescript
// Wybieramy tylko potrzebne kolumny (user_id i tak jest usuwany w DTO)
.select("id, front, back, source, generation_id, created_at, updated_at")
```

**Impact:**

- Mniejszy transfer danych: ~10-20% redukcji
- Szybsze parsowanie JSON
- Zalecane dla endpoint√≥w GET

### 4.2 Count optimization

**Obecne podej≈õcie:**

```typescript
.select("*", { count: "exact" })
```

**Problem:**

- `count: "exact"` wykonuje pe≈Çny COUNT(\*) - kosztowne dla du≈ºych tabel

**Alternatywa dla du≈ºych tabel:**

```typescript
// Dla <10,000 wierszy: exact (dok≈Çadny)
.select("*", { count: "exact" })

// Dla >10,000 wierszy: estimated (szacowany z EXPLAIN)
.select("*", { count: "estimated" })

// Lub: planned (u≈ºywa statystyk PostgreSQL)
.select("*", { count: "planned" })
```

**Rekomendacja:**

- U≈ºywaƒá `exact` dla ma≈Çych/≈õrednich tabel (<10,000)
- Prze≈ÇƒÖczyƒá na `estimated` gdy total przekroczy pr√≥g
- UI mo≈ºe pokazaƒá "~10,000 fiszek" zamiast dok≈Çadnej liczby

---

## 5. Cachowanie

### 5.1 HTTP Cache headers

**GET /api/flashcards:**

```typescript
return new Response(JSON.stringify(response), {
  status: 200,
  headers: {
    "Content-Type": "application/json",
    "Cache-Control": "private, max-age=60", // 1 minuta
    ETag: generateETag(response), // Opcjonalnie
  },
});
```

**Korzy≈õci:**

- PrzeglƒÖdarka cache dla powtarzajƒÖcych siƒô ≈ºƒÖda≈Ñ
- Redukcja obciƒÖ≈ºenia serwera o ~30-50%
- Szybsza odpowied≈∫ dla u≈ºytkownika

**Uniewa≈ºnianie:**

- POST/PATCH/DELETE automatycznie uniewa≈ºnia cache (inna metoda)
- ETag pozwala na walidacjƒô 304 Not Modified

### 5.2 Supabase cache (przysz≈Ça optymalizacja)

**Dla czƒôsto czytanych danych:**

```typescript
// Redis lub Memcached przed Supabase
const cacheKey = `flashcards:${user_id}:page:${page}`;
let data = await cache.get(cacheKey);

if (!data) {
  data = await supabase.from("flashcards")...;
  await cache.set(cacheKey, data, 60); // TTL 60s
}
```

**Rekomendacja:**

- Implementowaƒá tylko je≈õli serwer jest przeciƒÖ≈ºony
- Na razie Supabase connection pooling jest wystarczajƒÖcy

---

## 6. Monitoring i metryki

### 6.1 Kluczowe metryki do ≈õledzenia

**Wydajno≈õƒá:**

- Response time (p50, p95, p99):
  - Target p95: <500ms
  - Target p99: <1s
- Query execution time
- Database connection pool usage

**ObciƒÖ≈ºenie:**

- Requests per minute (per endpoint)
- Concurrent users
- Database connections

**B≈Çƒôdy:**

- Error rate by endpoint
- 4xx vs 5xx errors
- Database errors

### 6.2 Narzƒôdzia

**Supabase Dashboard:**

- Query performance
- Connection pool stats
- Error logs

**Application logging:**

```typescript
// Loguj wolne zapytania
const start = Date.now();
const result = await service.getFlashcards(...);
const duration = Date.now() - start;

if (duration > 500) {
  console.warn(`Slow query: GET /api/flashcards took ${duration}ms`);
}
```

**Rekomendowane alerty:**

- Response time p95 > 1s
- Error rate > 5%
- Database connections > 80% pool

---

## 7. Progi wydajno≈õciowe

### 7.1 Expected performance (obecna implementacja)

| Endpoint                       | Oczekiwany czas | Max akceptowalny |
| ------------------------------ | --------------- | ---------------- |
| GET /api/flashcards (page 1)   | <100ms          | 500ms            |
| GET /api/flashcards (page 100) | <500ms          | 2s               |
| GET /api/flashcards/:id        | <50ms           | 200ms            |
| POST /api/flashcards           | <100ms          | 500ms            |
| POST /api/flashcards/bulk (10) | <150ms          | 1s               |
| POST /api/flashcards/bulk (50) | <250ms          | 2s               |
| PATCH /api/flashcards/:id      | <100ms          | 500ms            |
| DELETE /api/flashcards/:id     | <50ms           | 200ms            |

### 7.2 Skalowalno≈õƒá

**Obecna architektura wspiera:**

- 1,000 u≈ºytkownik√≥w jednocze≈õnie
- 100,000 fiszek na u≈ºytkownika
- 10,000 ≈ºƒÖda≈Ñ/minutƒô

**Bottlenecki do monitorowania:**

- Supabase connection pool (domy≈õlnie: 15 po≈ÇƒÖcze≈Ñ)
- Database storage (200MB - 500GB na Supabase Free/Pro)
- API rate limits (brak obecnie, zalecane dodanie)

---

## 8. Podsumowanie rekomendacji

### 8.1 Krytyczne (implementowaƒá teraz)

1. ‚úÖ **Dodaƒá indeks na `updated_at`**
   - Migracja: `20251015000000_add_flashcards_indexes.sql`
   - Impact: Sortowanie po updated_at 10x szybsze

2. ‚úÖ **Dodaƒá indeks na `source`**
   - Ta sama migracja
   - Impact: Filtrowanie po source 3x szybsze

### 8.2 Wa≈ºne (implementowaƒá w ciƒÖgu miesiƒÖca)

3. üìã **Dodaƒá HTTP cache headers**
   - Proste, du≈ºy impact na UX
   - Redukcja obciƒÖ≈ºenia serwera

4. üìã **Zoptymalizowaƒá SELECT queries**
   - Wyb√≥r konkretnych kolumn zamiast \*
   - 10-20% redukcja transferu danych

5. üìã **Dodaƒá monitorowanie**
   - Logowanie wolnych zapyta≈Ñ (>500ms)
   - Metryki wydajno≈õci
   - Alerty dla anomalii

### 8.3 Opcjonalne (wed≈Çug potrzeb)

6. üîÆ **Indeks z≈Ço≈ºony `(user_id, source, created_at)`**
   - Tylko je≈õli filtrowanie po source jest popularne
   - Wiƒôkszy rozmiar, wiƒôksza wydajno≈õƒá

7. üîÆ **Cursor-based pagination**
   - Tylko dla u≈ºytkownik√≥w z >10,000 fiszkami
   - Wymaga zmian w API i frontend

8. üîÆ **Distributed caching (Redis)**
   - Tylko je≈õli serwer jest przeciƒÖ≈ºony
   - Dodatkowa z≈Ço≈ºono≈õƒá infrastruktury

---

## 9. Plan implementacji

### Faza 1: Podstawowe indeksy (dzisiaj)

- [x] Utworzenie migracji dla indeks√≥w
- [ ] Przetestowanie na staging
- [ ] Deploy na produkcjƒô
- [ ] Weryfikacja metryk wydajno≈õci

### Faza 2: Optymalizacja zapyta≈Ñ (tydzie≈Ñ 1)

- [ ] Dodanie cache headers
- [ ] Optymalizacja SELECT queries
- [ ] Implementacja logowania wolnych zapyta≈Ñ

### Faza 3: Monitoring (tydzie≈Ñ 2)

- [ ] Konfiguracja dashboardu metryk
- [ ] Ustawienie alert√≥w
- [ ] Dokumentacja runbook'√≥w

### Faza 4: Zaawansowana optymalizacja (wed≈Çug potrzeb)

- [ ] Ocena potrzeby cursor-based pagination
- [ ] Ocena potrzeby distributed caching
- [ ] Load testing i stress testing

---

**Status:** Migracja z podstawowymi indeksami gotowa do wdro≈ºenia  
**Nastƒôpny krok:** Deploy migracji na staging
